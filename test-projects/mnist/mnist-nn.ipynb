{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe173fd-03dd-416d-b07d-affb74e98005",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torch) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torchvision) (2.2.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aadil/Documents/Workspace/ml-learning-projects/venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dddd757a-e06f-460c-94c8-734a4dccf816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31ced219-9690-4f14-963e-5d4ac6b8d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # resize\n",
    "    transforms.Resize(28),\n",
    "    # center-crop\n",
    "    transforms.CenterCrop(28),\n",
    "    # to-tensor\n",
    "    transforms.ToTensor(),\n",
    "    # normalize\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c54ade9-e120-4dee-9993-ec3cfb936b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d684d1b2-40db-41dc-9b9f-19bbc697ab42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 1, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    # print(img)\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "054987e0-56e7-449c-b6db-1b807edc006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7043ca08-2eba-4358-9ec2-bc35e93db46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9eff3a88-32cd-4b98-9f1b-825199726340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2385010\n"
     ]
    }
   ],
   "source": [
    "n = 28 * 28\n",
    "n_hidden = 3000\n",
    "n_outputs = 10\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "W1 = torch.randn((n, n_hidden)) * (1.0 / torch.sqrt(torch.tensor(n, dtype=torch.float32)))\n",
    "b1 = torch.randn((1, n_hidden))\n",
    "W2 = torch.randn((n_hidden, n_outputs)) * (1.0 / torch.sqrt(torch.tensor(n_hidden, dtype=torch.float32)))\n",
    "b2 = torch.randn((1, n_outputs))\n",
    "batch_size = 64\n",
    "\n",
    "parameters = [W1, b1, W2, b2]\n",
    "\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a82286e6-7ad4-4f2f-9ea6-b61c445c255e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50000; loss=3.0350077152252197\n",
      "100/50000; loss=0.7424196600914001\n",
      "200/50000; loss=0.4825699031352997\n",
      "300/50000; loss=0.36728546023368835\n",
      "400/50000; loss=0.2472168505191803\n",
      "500/50000; loss=0.27350887656211853\n",
      "600/50000; loss=0.2644270956516266\n",
      "700/50000; loss=0.39904850721359253\n",
      "800/50000; loss=0.40185779333114624\n",
      "900/50000; loss=0.45685169100761414\n",
      "1000/50000; loss=0.2969614565372467\n",
      "1100/50000; loss=0.41255253553390503\n",
      "1200/50000; loss=0.3473416268825531\n",
      "1300/50000; loss=0.3254193961620331\n",
      "1400/50000; loss=0.4665276110172272\n",
      "1500/50000; loss=0.32677140831947327\n",
      "1600/50000; loss=0.1929471343755722\n",
      "1700/50000; loss=0.29787498712539673\n",
      "1800/50000; loss=0.21959686279296875\n",
      "1900/50000; loss=0.25730928778648376\n",
      "2000/50000; loss=0.17123626172542572\n",
      "2100/50000; loss=0.3819717466831207\n",
      "2200/50000; loss=0.19093218445777893\n",
      "2300/50000; loss=0.32230907678604126\n",
      "2400/50000; loss=0.257625550031662\n",
      "2500/50000; loss=0.28718024492263794\n",
      "2600/50000; loss=0.3265162408351898\n",
      "2700/50000; loss=0.2935381233692169\n",
      "2800/50000; loss=0.11943183094263077\n",
      "2900/50000; loss=0.34694603085517883\n",
      "3000/50000; loss=0.22483064234256744\n",
      "3100/50000; loss=0.20566126704216003\n",
      "3200/50000; loss=0.24864695966243744\n",
      "3300/50000; loss=0.11521707475185394\n",
      "3400/50000; loss=0.11921493709087372\n",
      "3500/50000; loss=0.48186782002449036\n",
      "3600/50000; loss=0.12190049141645432\n",
      "3700/50000; loss=0.20956288278102875\n",
      "3800/50000; loss=0.12156858295202255\n",
      "3900/50000; loss=0.22425369918346405\n",
      "4000/50000; loss=0.21749278903007507\n",
      "4100/50000; loss=0.18034003674983978\n",
      "4200/50000; loss=0.33047425746917725\n",
      "4300/50000; loss=0.2094554305076599\n",
      "4400/50000; loss=0.1991829127073288\n",
      "4500/50000; loss=0.22622397541999817\n",
      "4600/50000; loss=0.22337813675403595\n",
      "4700/50000; loss=0.21925196051597595\n",
      "4800/50000; loss=0.15992359817028046\n",
      "4900/50000; loss=0.1574474573135376\n",
      "5000/50000; loss=0.19385896623134613\n",
      "5100/50000; loss=0.10500095784664154\n",
      "5200/50000; loss=0.15971048176288605\n",
      "5300/50000; loss=0.08811119198799133\n",
      "5400/50000; loss=0.2344781458377838\n",
      "5500/50000; loss=0.147746279835701\n",
      "5600/50000; loss=0.2655828595161438\n",
      "5700/50000; loss=0.24487046897411346\n",
      "5800/50000; loss=0.12917065620422363\n",
      "5900/50000; loss=0.07703451067209244\n",
      "6000/50000; loss=0.08791828155517578\n",
      "6100/50000; loss=0.263942152261734\n",
      "6200/50000; loss=0.26749661564826965\n",
      "6300/50000; loss=0.22520820796489716\n",
      "6400/50000; loss=0.16973410546779633\n",
      "6500/50000; loss=0.1348073035478592\n",
      "6600/50000; loss=0.08870520442724228\n",
      "6700/50000; loss=0.15100198984146118\n",
      "6800/50000; loss=0.1764477640390396\n",
      "6900/50000; loss=0.19049958884716034\n",
      "7000/50000; loss=0.09211789071559906\n",
      "7100/50000; loss=0.16362148523330688\n",
      "7200/50000; loss=0.29400721192359924\n",
      "7300/50000; loss=0.07218219339847565\n",
      "7400/50000; loss=0.15233923494815826\n",
      "7500/50000; loss=0.19405332207679749\n",
      "7600/50000; loss=0.07697320729494095\n",
      "7700/50000; loss=0.0892925038933754\n",
      "7800/50000; loss=0.043063532561063766\n",
      "7900/50000; loss=0.14343583583831787\n",
      "8000/50000; loss=0.1656082421541214\n",
      "8100/50000; loss=0.12938936054706573\n",
      "8200/50000; loss=0.28677088022232056\n",
      "8300/50000; loss=0.15398338437080383\n",
      "8400/50000; loss=0.25788190960884094\n",
      "8500/50000; loss=0.09999281167984009\n",
      "8600/50000; loss=0.22419831156730652\n",
      "8700/50000; loss=0.27626070380210876\n",
      "8800/50000; loss=0.12169785797595978\n",
      "8900/50000; loss=0.19724228978157043\n",
      "9000/50000; loss=0.27176985144615173\n",
      "9100/50000; loss=0.15589593350887299\n",
      "9200/50000; loss=0.06728196144104004\n",
      "9300/50000; loss=0.1506360024213791\n",
      "9400/50000; loss=0.1859859824180603\n",
      "9500/50000; loss=0.2981318235397339\n",
      "9600/50000; loss=0.1560426652431488\n",
      "9700/50000; loss=0.15563422441482544\n",
      "9800/50000; loss=0.20201730728149414\n",
      "9900/50000; loss=0.0944104790687561\n",
      "10000/50000; loss=0.08536674827337265\n",
      "10100/50000; loss=0.09650024771690369\n",
      "10200/50000; loss=0.09710809588432312\n",
      "10300/50000; loss=0.10009238123893738\n",
      "10400/50000; loss=0.07684790343046188\n",
      "10500/50000; loss=0.0526406392455101\n",
      "10600/50000; loss=0.08419037610292435\n",
      "10700/50000; loss=0.16808050870895386\n",
      "10800/50000; loss=0.17997214198112488\n",
      "10900/50000; loss=0.14649099111557007\n",
      "11000/50000; loss=0.17283889651298523\n",
      "11100/50000; loss=0.06945885717868805\n",
      "11200/50000; loss=0.051104847341775894\n",
      "11300/50000; loss=0.16234809160232544\n",
      "11400/50000; loss=0.14713497459888458\n",
      "11500/50000; loss=0.14991554617881775\n",
      "11600/50000; loss=0.14244140684604645\n",
      "11700/50000; loss=0.18025565147399902\n",
      "11800/50000; loss=0.180787593126297\n",
      "11900/50000; loss=0.17091865837574005\n",
      "12000/50000; loss=0.14139163494110107\n",
      "12100/50000; loss=0.09722711145877838\n",
      "12200/50000; loss=0.11111485958099365\n",
      "12300/50000; loss=0.09515435993671417\n",
      "12400/50000; loss=0.2120409458875656\n",
      "12500/50000; loss=0.0685119703412056\n",
      "12600/50000; loss=0.07932128012180328\n",
      "12700/50000; loss=0.09848043322563171\n",
      "12800/50000; loss=0.12465158849954605\n",
      "12900/50000; loss=0.19210098683834076\n",
      "13000/50000; loss=0.0781531035900116\n",
      "13100/50000; loss=0.11920183151960373\n",
      "13200/50000; loss=0.09263286739587784\n",
      "13300/50000; loss=0.06682305783033371\n",
      "13400/50000; loss=0.2171868085861206\n",
      "13500/50000; loss=0.23058432340621948\n",
      "13600/50000; loss=0.09510096907615662\n",
      "13700/50000; loss=0.15803220868110657\n",
      "13800/50000; loss=0.1706535965204239\n",
      "13900/50000; loss=0.042391370981931686\n",
      "14000/50000; loss=0.16077975928783417\n",
      "14100/50000; loss=0.13941437005996704\n",
      "14200/50000; loss=0.14352720975875854\n",
      "14300/50000; loss=0.08991645276546478\n",
      "14400/50000; loss=0.12512144446372986\n",
      "14500/50000; loss=0.08359260112047195\n",
      "14600/50000; loss=0.20513661205768585\n",
      "14700/50000; loss=0.0904286801815033\n",
      "14800/50000; loss=0.10922396183013916\n",
      "14900/50000; loss=0.05460156127810478\n",
      "15000/50000; loss=0.1070900708436966\n",
      "15100/50000; loss=0.05804784223437309\n",
      "15200/50000; loss=0.04482564702630043\n",
      "15300/50000; loss=0.06594620645046234\n",
      "15400/50000; loss=0.14094559848308563\n",
      "15500/50000; loss=0.08698692172765732\n",
      "15600/50000; loss=0.07412660121917725\n",
      "15700/50000; loss=0.07347461581230164\n",
      "15800/50000; loss=0.090960793197155\n",
      "15900/50000; loss=0.05948570370674133\n",
      "16000/50000; loss=0.1416875720024109\n",
      "16100/50000; loss=0.058353010565042496\n",
      "16200/50000; loss=0.3102415204048157\n",
      "16300/50000; loss=0.06603100895881653\n",
      "16400/50000; loss=0.09483841806650162\n",
      "16500/50000; loss=0.08086147159337997\n",
      "16600/50000; loss=0.14594970643520355\n",
      "16700/50000; loss=0.10705254226922989\n",
      "16800/50000; loss=0.10165029019117355\n",
      "16900/50000; loss=0.07743045687675476\n",
      "17000/50000; loss=0.05909690260887146\n",
      "17100/50000; loss=0.043612126260995865\n",
      "17200/50000; loss=0.04451613128185272\n",
      "17300/50000; loss=0.06059480831027031\n",
      "17400/50000; loss=0.14378315210342407\n",
      "17500/50000; loss=0.06347183883190155\n",
      "17600/50000; loss=0.021579304710030556\n",
      "17700/50000; loss=0.054485857486724854\n",
      "17800/50000; loss=0.07418989390134811\n",
      "17900/50000; loss=0.06419290602207184\n",
      "18000/50000; loss=0.032728128135204315\n",
      "18100/50000; loss=0.14258769154548645\n",
      "18200/50000; loss=0.09866632521152496\n",
      "18300/50000; loss=0.021114788949489594\n",
      "18400/50000; loss=0.054673731327056885\n",
      "18500/50000; loss=0.026867857202887535\n",
      "18600/50000; loss=0.09953344613313675\n",
      "18700/50000; loss=0.033268023282289505\n",
      "18800/50000; loss=0.14580191671848297\n",
      "18900/50000; loss=0.10753726214170456\n",
      "19000/50000; loss=0.04612879082560539\n",
      "19100/50000; loss=0.04204123467206955\n",
      "19200/50000; loss=0.02790989726781845\n",
      "19300/50000; loss=0.05540712550282478\n",
      "19400/50000; loss=0.05935097858309746\n",
      "19500/50000; loss=0.14593768119812012\n",
      "19600/50000; loss=0.1073584035038948\n",
      "19700/50000; loss=0.05295483022928238\n",
      "19800/50000; loss=0.11799529194831848\n",
      "19900/50000; loss=0.03727865219116211\n",
      "20000/50000; loss=0.11532532423734665\n",
      "20100/50000; loss=0.03160868585109711\n",
      "20200/50000; loss=0.05302143469452858\n",
      "20300/50000; loss=0.1944350153207779\n",
      "20400/50000; loss=0.03558305278420448\n",
      "20500/50000; loss=0.050636108964681625\n",
      "20600/50000; loss=0.05071721598505974\n",
      "20700/50000; loss=0.12637653946876526\n",
      "20800/50000; loss=0.047062233090400696\n",
      "20900/50000; loss=0.06303024291992188\n",
      "21000/50000; loss=0.03986438363790512\n",
      "21100/50000; loss=0.07375100255012512\n",
      "21200/50000; loss=0.05975298956036568\n",
      "21300/50000; loss=0.09993452578783035\n",
      "21400/50000; loss=0.09893565624952316\n",
      "21500/50000; loss=0.06775685399770737\n",
      "21600/50000; loss=0.1059318408370018\n",
      "21700/50000; loss=0.04444434121251106\n",
      "21800/50000; loss=0.181925430893898\n",
      "21900/50000; loss=0.04162533953785896\n",
      "22000/50000; loss=0.03843659535050392\n",
      "22100/50000; loss=0.06375017017126083\n",
      "22200/50000; loss=0.015927821397781372\n",
      "22300/50000; loss=0.09275008738040924\n",
      "22400/50000; loss=0.14362892508506775\n",
      "22500/50000; loss=0.03160107880830765\n",
      "22600/50000; loss=0.12849798798561096\n",
      "22700/50000; loss=0.1187707930803299\n",
      "22800/50000; loss=0.054997362196445465\n",
      "22900/50000; loss=0.09400251507759094\n",
      "23000/50000; loss=0.05608854442834854\n",
      "23100/50000; loss=0.026526793837547302\n",
      "23200/50000; loss=0.043328456580638885\n",
      "23300/50000; loss=0.11074551939964294\n",
      "23400/50000; loss=0.06851062178611755\n",
      "23500/50000; loss=0.03681539371609688\n",
      "23600/50000; loss=0.11750055104494095\n",
      "23700/50000; loss=0.0715300515294075\n",
      "23800/50000; loss=0.09075181931257248\n",
      "23900/50000; loss=0.0353408120572567\n",
      "24000/50000; loss=0.08009708672761917\n",
      "24100/50000; loss=0.04876464977860451\n",
      "24200/50000; loss=0.03154213726520538\n",
      "24300/50000; loss=0.049714453518390656\n",
      "24400/50000; loss=0.027354633435606956\n",
      "24500/50000; loss=0.04817046597599983\n",
      "24600/50000; loss=0.0654171034693718\n",
      "24700/50000; loss=0.04104374349117279\n",
      "24800/50000; loss=0.026640715077519417\n",
      "24900/50000; loss=0.023525334894657135\n",
      "25000/50000; loss=0.03654513880610466\n",
      "25100/50000; loss=0.02981705218553543\n",
      "25200/50000; loss=0.11452187597751617\n",
      "25300/50000; loss=0.06282416731119156\n",
      "25400/50000; loss=0.09649695456027985\n",
      "25500/50000; loss=0.03598619997501373\n",
      "25600/50000; loss=0.07273541390895844\n",
      "25700/50000; loss=0.04841958358883858\n",
      "25800/50000; loss=0.03519216924905777\n",
      "25900/50000; loss=0.03828543797135353\n",
      "26000/50000; loss=0.1139780655503273\n",
      "26100/50000; loss=0.023975251242518425\n",
      "26200/50000; loss=0.04577288776636124\n",
      "26300/50000; loss=0.05606057494878769\n",
      "26400/50000; loss=0.06281053274869919\n",
      "26500/50000; loss=0.2652936577796936\n",
      "26600/50000; loss=0.028544122353196144\n",
      "26700/50000; loss=0.06360463052988052\n",
      "26800/50000; loss=0.037260085344314575\n",
      "26900/50000; loss=0.10647930204868317\n",
      "27000/50000; loss=0.062074437737464905\n",
      "27100/50000; loss=0.06215294077992439\n",
      "27200/50000; loss=0.046388108283281326\n",
      "27300/50000; loss=0.052175939083099365\n",
      "27400/50000; loss=0.05375387892127037\n",
      "27500/50000; loss=0.060569100081920624\n",
      "27600/50000; loss=0.032519493252038956\n",
      "27700/50000; loss=0.12505023181438446\n",
      "27800/50000; loss=0.13451257348060608\n",
      "27900/50000; loss=0.03591349720954895\n",
      "28000/50000; loss=0.01666168123483658\n",
      "28100/50000; loss=0.04232480376958847\n",
      "28200/50000; loss=0.03442821279168129\n",
      "28300/50000; loss=0.09631229937076569\n",
      "28400/50000; loss=0.04254768788814545\n",
      "28500/50000; loss=0.14292706549167633\n",
      "28600/50000; loss=0.1313948780298233\n",
      "28700/50000; loss=0.08565312623977661\n",
      "28800/50000; loss=0.06716657429933548\n",
      "28900/50000; loss=0.047372493892908096\n",
      "29000/50000; loss=0.019900377839803696\n",
      "29100/50000; loss=0.025666678324341774\n",
      "29200/50000; loss=0.022658074274659157\n",
      "29300/50000; loss=0.020907852798700333\n",
      "29400/50000; loss=0.022689903154969215\n",
      "29500/50000; loss=0.023558782413601875\n",
      "29600/50000; loss=0.025222595781087875\n",
      "29700/50000; loss=0.02265426330268383\n",
      "29800/50000; loss=0.04282296448945999\n",
      "29900/50000; loss=0.0715281069278717\n",
      "30000/50000; loss=0.03468504548072815\n",
      "30100/50000; loss=0.07992476969957352\n",
      "30200/50000; loss=0.0708770751953125\n",
      "30300/50000; loss=0.053812552243471146\n",
      "30400/50000; loss=0.04831472039222717\n",
      "30500/50000; loss=0.13348688185214996\n",
      "30600/50000; loss=0.0425935797393322\n",
      "30700/50000; loss=0.09681092202663422\n",
      "30800/50000; loss=0.1429598182439804\n",
      "30900/50000; loss=0.05221434682607651\n",
      "31000/50000; loss=0.09408614039421082\n",
      "31100/50000; loss=0.023454908281564713\n",
      "31200/50000; loss=0.03610565513372421\n",
      "31300/50000; loss=0.08001681417226791\n",
      "31400/50000; loss=0.047876302152872086\n",
      "31500/50000; loss=0.05837639048695564\n",
      "31600/50000; loss=0.04971963167190552\n",
      "31700/50000; loss=0.0409531369805336\n",
      "31800/50000; loss=0.07429502159357071\n",
      "31900/50000; loss=0.04414762556552887\n",
      "32000/50000; loss=0.08802222460508347\n",
      "32100/50000; loss=0.04474882036447525\n",
      "32200/50000; loss=0.042155586183071136\n",
      "32300/50000; loss=0.026079921051859856\n",
      "32400/50000; loss=0.05640752241015434\n",
      "32500/50000; loss=0.12789058685302734\n",
      "32600/50000; loss=0.03928843140602112\n",
      "32700/50000; loss=0.03230439871549606\n",
      "32800/50000; loss=0.017755165696144104\n",
      "32900/50000; loss=0.020500006154179573\n",
      "33000/50000; loss=0.04738462343811989\n",
      "33100/50000; loss=0.02667093276977539\n",
      "33200/50000; loss=0.04255463555455208\n",
      "33300/50000; loss=0.026633650064468384\n",
      "33400/50000; loss=0.020273718982934952\n",
      "33500/50000; loss=0.12252992391586304\n",
      "33600/50000; loss=0.055043138563632965\n",
      "33700/50000; loss=0.016399085521697998\n",
      "33800/50000; loss=0.014873616397380829\n",
      "33900/50000; loss=0.01061927154660225\n",
      "34000/50000; loss=0.022965963929891586\n",
      "34100/50000; loss=0.048680517822504044\n",
      "34200/50000; loss=0.07904024422168732\n",
      "34300/50000; loss=0.03809896856546402\n",
      "34400/50000; loss=0.040781524032354355\n",
      "34500/50000; loss=0.09101489931344986\n",
      "34600/50000; loss=0.06486241519451141\n",
      "34700/50000; loss=0.02724599651992321\n",
      "34800/50000; loss=0.028504764661192894\n",
      "34900/50000; loss=0.021981043741106987\n",
      "35000/50000; loss=0.03197076544165611\n",
      "35100/50000; loss=0.01507976371794939\n",
      "35200/50000; loss=0.022654330357909203\n",
      "35300/50000; loss=0.026585277169942856\n",
      "35400/50000; loss=0.017527418211102486\n",
      "35500/50000; loss=0.0462278388440609\n",
      "35600/50000; loss=0.025805700570344925\n",
      "35700/50000; loss=0.04044415429234505\n",
      "35800/50000; loss=0.028514370322227478\n",
      "35900/50000; loss=0.06306006014347076\n",
      "36000/50000; loss=0.059259526431560516\n",
      "36100/50000; loss=0.0133510148152709\n",
      "36200/50000; loss=0.05563414841890335\n",
      "36300/50000; loss=0.09275071322917938\n",
      "36400/50000; loss=0.040852244943380356\n",
      "36500/50000; loss=0.012949557043612003\n",
      "36600/50000; loss=0.047781698405742645\n",
      "36700/50000; loss=0.02107199653983116\n",
      "36800/50000; loss=0.01503536943346262\n",
      "36900/50000; loss=0.024039996787905693\n",
      "37000/50000; loss=0.04202704876661301\n",
      "37100/50000; loss=0.026213545352220535\n",
      "37200/50000; loss=0.0381036214530468\n",
      "37300/50000; loss=0.03210935741662979\n",
      "37400/50000; loss=0.02087767980992794\n",
      "37500/50000; loss=0.012354237958788872\n",
      "37600/50000; loss=0.10548442602157593\n",
      "37700/50000; loss=0.02567022480070591\n",
      "37800/50000; loss=0.020344583317637444\n",
      "37900/50000; loss=0.013717703521251678\n",
      "38000/50000; loss=0.022446468472480774\n",
      "38100/50000; loss=0.05601998418569565\n",
      "38200/50000; loss=0.023449145257472992\n",
      "38300/50000; loss=0.0414261557161808\n",
      "38400/50000; loss=0.021404564380645752\n",
      "38500/50000; loss=0.06079079583287239\n",
      "38600/50000; loss=0.02543260157108307\n",
      "38700/50000; loss=0.02594427764415741\n",
      "38800/50000; loss=0.029255347326397896\n",
      "38900/50000; loss=0.018963979557156563\n",
      "39000/50000; loss=0.023836668580770493\n",
      "39100/50000; loss=0.0885624885559082\n",
      "39200/50000; loss=0.02011837810277939\n",
      "39300/50000; loss=0.011960543692111969\n",
      "39400/50000; loss=0.01252138614654541\n",
      "39500/50000; loss=0.040242839604616165\n",
      "39600/50000; loss=0.05851469188928604\n",
      "39700/50000; loss=0.04301165044307709\n",
      "39800/50000; loss=0.0187115129083395\n",
      "39900/50000; loss=0.028731904923915863\n",
      "40000/50000; loss=0.029879435896873474\n",
      "40100/50000; loss=0.027032945305109024\n",
      "40200/50000; loss=0.008870350196957588\n",
      "40300/50000; loss=0.012414727360010147\n",
      "40400/50000; loss=0.010606824420392513\n",
      "40500/50000; loss=0.04640309512615204\n",
      "40600/50000; loss=0.04790611192584038\n",
      "40700/50000; loss=0.04100819677114487\n",
      "40800/50000; loss=0.024522321298718452\n",
      "40900/50000; loss=0.05829011648893356\n",
      "41000/50000; loss=0.08481403440237045\n",
      "41100/50000; loss=0.03016706183552742\n",
      "41200/50000; loss=0.014397252351045609\n",
      "41300/50000; loss=0.020998036488890648\n",
      "41400/50000; loss=0.025261027738451958\n",
      "41500/50000; loss=0.01187148317694664\n",
      "41600/50000; loss=0.009386628866195679\n",
      "41700/50000; loss=0.018392084166407585\n",
      "41800/50000; loss=0.023251034319400787\n",
      "41900/50000; loss=0.05970830097794533\n",
      "42000/50000; loss=0.013332165777683258\n",
      "42100/50000; loss=0.023790055885910988\n",
      "42200/50000; loss=0.023897729814052582\n",
      "42300/50000; loss=0.021949535235762596\n",
      "42400/50000; loss=0.04037012904882431\n",
      "42500/50000; loss=0.06306891143321991\n",
      "42600/50000; loss=0.015868663787841797\n",
      "42700/50000; loss=0.08412113040685654\n",
      "42800/50000; loss=0.026409689337015152\n",
      "42900/50000; loss=0.10051150619983673\n",
      "43000/50000; loss=0.05597030371427536\n",
      "43100/50000; loss=0.05237240716814995\n",
      "43200/50000; loss=0.023272207006812096\n",
      "43300/50000; loss=0.008532379753887653\n",
      "43400/50000; loss=0.06637205928564072\n",
      "43500/50000; loss=0.017044469714164734\n",
      "43600/50000; loss=0.017413198947906494\n",
      "43700/50000; loss=0.013970572501420975\n",
      "43800/50000; loss=0.01679721288383007\n",
      "43900/50000; loss=0.017973074689507484\n",
      "44000/50000; loss=0.020749704912304878\n",
      "44100/50000; loss=0.01858067698776722\n",
      "44200/50000; loss=0.08444001525640488\n",
      "44300/50000; loss=0.01509115844964981\n",
      "44400/50000; loss=0.018879484385252\n",
      "44500/50000; loss=0.024727631360292435\n",
      "44600/50000; loss=0.02122197113931179\n",
      "44700/50000; loss=0.015199421904981136\n",
      "44800/50000; loss=0.02308175526559353\n",
      "44900/50000; loss=0.019080210477113724\n",
      "45000/50000; loss=0.02867535874247551\n",
      "45100/50000; loss=0.04483133926987648\n",
      "45200/50000; loss=0.03475259989500046\n",
      "45300/50000; loss=0.05388399586081505\n",
      "45400/50000; loss=0.025695601478219032\n",
      "45500/50000; loss=0.01583300530910492\n",
      "45600/50000; loss=0.016470784321427345\n",
      "45700/50000; loss=0.03532707318663597\n",
      "45800/50000; loss=0.016687195748090744\n",
      "45900/50000; loss=0.025660298764705658\n",
      "46000/50000; loss=0.06712693721055984\n",
      "46100/50000; loss=0.012005077674984932\n",
      "46200/50000; loss=0.015299567021429539\n",
      "46300/50000; loss=0.040525682270526886\n",
      "46400/50000; loss=0.014260631054639816\n",
      "46500/50000; loss=0.013069095090031624\n",
      "46600/50000; loss=0.03632901981472969\n",
      "46700/50000; loss=0.019506122916936874\n",
      "46800/50000; loss=0.028467664495110512\n",
      "46900/50000; loss=0.020504504442214966\n",
      "47000/50000; loss=0.053097158670425415\n",
      "47100/50000; loss=0.044210661202669144\n",
      "47200/50000; loss=0.04356623813509941\n",
      "47300/50000; loss=0.09469734877347946\n",
      "47400/50000; loss=0.04487135633826256\n",
      "47500/50000; loss=0.00987135898321867\n",
      "47600/50000; loss=0.16090640425682068\n",
      "47700/50000; loss=0.018322115764021873\n",
      "47800/50000; loss=0.03027522750198841\n",
      "47900/50000; loss=0.012046890333294868\n",
      "48000/50000; loss=0.0639575719833374\n",
      "48100/50000; loss=0.0458526685833931\n",
      "48200/50000; loss=0.02688254415988922\n",
      "48300/50000; loss=0.021293604746460915\n",
      "48400/50000; loss=0.03069986402988434\n",
      "48500/50000; loss=0.05172797292470932\n",
      "48600/50000; loss=0.034551143646240234\n",
      "48700/50000; loss=0.015961121767759323\n",
      "48800/50000; loss=0.030038924887776375\n",
      "48900/50000; loss=0.008405114524066448\n",
      "49000/50000; loss=0.07187741994857788\n",
      "49100/50000; loss=0.01719193533062935\n",
      "49200/50000; loss=0.03231020271778107\n",
      "49300/50000; loss=0.014723347499966621\n",
      "49400/50000; loss=0.02795376256108284\n",
      "49500/50000; loss=0.06916552037000656\n",
      "49600/50000; loss=0.0559101365506649\n",
      "49700/50000; loss=0.050272244960069656\n",
      "49800/50000; loss=0.03490101546049118\n",
      "49900/50000; loss=0.02925712615251541\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "steps = 50000\n",
    "for step in range(steps):\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    x = train_features.squeeze()\n",
    "    x_vec = x.view((batch_size, n))\n",
    "    h1 = x_vec @ W1 + b1\n",
    "    h1_activated = torch.relu(h1)\n",
    "    logits = h1_activated @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, train_labels)\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= learning_rate * p.grad\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"{step}/{steps}; loss={loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "51153214-64c6-4604-ae39-a7af56789cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected label: 3; got label: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "img = test_features.squeeze()[0]\n",
    "label = test_labels[0]\n",
    "img_vec = img.view((-1, n))\n",
    "h1 = img_vec @ W1 + b1\n",
    "h1_activated = torch.tanh(h1)\n",
    "h2 = h1_activated @ W2 + b2\n",
    "probs = h2.softmax(dim=1)\n",
    "ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "\n",
    "print(f\"Expected label: {label}; got label: {ix}\")\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "45ff06ff-2758-4ee2-81c7-4b0eab98d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 2.0476\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "    for test_features, test_labels in test_dataloader:\n",
    "        test_features = test_features.squeeze()  # Remove unnecessary channel dimension\n",
    "        batch_size = test_features.shape[0]\n",
    "        n = test_features.numel() // batch_size  # Flatten dimension calculation\n",
    "\n",
    "        # Reshape input (flatten images)\n",
    "        x_vec = test_features.view(batch_size, -1)  # Shape: (batch_size, n)\n",
    "\n",
    "        # Forward pass\n",
    "        h1 = x_vec @ W1 + b1\n",
    "        h1_activated = torch.tanh(h1)\n",
    "        h2 = h1_activated @ W2 + b2\n",
    "        h2_activated = F.softmax(h2, dim=1)  # Output probabilities\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(h2_activated, test_labels)  # Compute batch loss\n",
    "        test_loss += loss.item() * batch_size  # Sum up weighted batch loss\n",
    "        total_samples += batch_size\n",
    "\n",
    "# Compute average loss\n",
    "average_test_loss = test_loss / total_samples\n",
    "print(f\"Average Test Loss: {average_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4ac2c6b6-2a77-471f-8d84-77514ddb2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "\n",
    "        # Hidden layers with ReLU activation\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size  \n",
    "\n",
    "        # Output layer (no activation, handled by CrossEntropyLoss)\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "\n",
    "        # Combine into Sequential model\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_model(model, train_dataloader, device=\"cpu\", learning_rate=0.01):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        images = images.view(images.shape[0], -1)  # Flatten images\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_dataloader)\n",
    "\n",
    "def evaluate_model(model, test_dataloader, device=\"cpu\"):\n",
    "    correct, total = 0, 0\n",
    "    test_loss = 0\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            logits = model(images)\n",
    "            test_loss += loss_fn(logits, labels).item()\n",
    "\n",
    "            predicted = logits.argmax(dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = test_loss / len(test_dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter optimization space\n",
    "    input_size = 28 * 28\n",
    "    output_size = 10\n",
    "    # Define search spaces\n",
    "    hidden_layers = []\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)  # Search 1-3 hidden layers\n",
    "    for _ in range(num_layers):\n",
    "        hidden_layers.append(trial.suggest_int(\"hidden_layer_size\", 32, 512))  # Search for neurons between 32 and 512\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1)  # Log scale search space\n",
    "\n",
    "    # Create Model\n",
    "    model = MLP(input_size, hidden_layers, output_size)\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_model(model, train_dataloader, learning_rate=learning_rate)\n",
    "    \n",
    "    # Evaluation\n",
    "    val_loss, val_accuracy = evaluate_model(model, test_dataloader)\n",
    "    \n",
    "    # Return the validation loss as the objective to minimize\n",
    "    return val_loss  # Or use val_accuracy to maximize instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "95bb5f9b-6fee-46d4-b655-122e39096300",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 22:53:58,523] A new study created in memory with name: no-name-9b3a719f-9996-4d57-a413-5e28a2defa0f\n",
      "[I 2025-03-10 22:54:02,184] Trial 0 finished with value: 0.3125288727082265 and parameters: {'num_layers': 1, 'hidden_layer_size': 66, 'learning_rate': 0.0004272276802226957}. Best is trial 0 with value: 0.3125288727082265.\n",
      "[I 2025-03-10 22:54:08,251] Trial 1 finished with value: 2.30581873541425 and parameters: {'num_layers': 3, 'hidden_layer_size': 508, 'learning_rate': 0.08950705014219264}. Best is trial 0 with value: 0.3125288727082265.\n",
      "[I 2025-03-10 22:54:13,071] Trial 2 finished with value: 0.24748259308231865 and parameters: {'num_layers': 3, 'hidden_layer_size': 326, 'learning_rate': 0.007842227595957995}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:17,027] Trial 3 finished with value: 0.7288226004998395 and parameters: {'num_layers': 1, 'hidden_layer_size': 504, 'learning_rate': 0.04387233981288631}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:20,805] Trial 4 finished with value: 1.779696813054905 and parameters: {'num_layers': 2, 'hidden_layer_size': 188, 'learning_rate': 0.06112078240394805}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:24,416] Trial 5 finished with value: 0.721377518526308 and parameters: {'num_layers': 1, 'hidden_layer_size': 175, 'learning_rate': 0.030411853327659878}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:30,042] Trial 6 finished with value: 2.306029734338165 and parameters: {'num_layers': 4, 'hidden_layer_size': 480, 'learning_rate': 0.08342449300809714}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:33,862] Trial 7 finished with value: 0.37441845589382633 and parameters: {'num_layers': 1, 'hidden_layer_size': 398, 'learning_rate': 0.014517068306160721}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:38,286] Trial 8 finished with value: 2.3020488684344445 and parameters: {'num_layers': 4, 'hidden_layer_size': 268, 'learning_rate': 0.06945835585651171}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:43,205] Trial 9 finished with value: 2.3042381037572386 and parameters: {'num_layers': 4, 'hidden_layer_size': 274, 'learning_rate': 0.06100857656633774}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:48,142] Trial 10 finished with value: 2.301569531677635 and parameters: {'num_layers': 3, 'hidden_layer_size': 360, 'learning_rate': 0.025157959852305945}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:51,927] Trial 11 finished with value: 0.2814658738340542 and parameters: {'num_layers': 2, 'hidden_layer_size': 41, 'learning_rate': 0.0008232896728014145}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:54:56,122] Trial 12 finished with value: 0.35567859441611416 and parameters: {'num_layers': 2, 'hidden_layer_size': 32, 'learning_rate': 0.00031752864638499335}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:00,093] Trial 13 finished with value: 0.43029684649341426 and parameters: {'num_layers': 3, 'hidden_layer_size': 128, 'learning_rate': 0.01725703645657388}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:04,551] Trial 14 finished with value: 2.306840135793018 and parameters: {'num_layers': 2, 'hidden_layer_size': 291, 'learning_rate': 0.042223182131197703}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:09,326] Trial 15 finished with value: 0.329558109591721 and parameters: {'num_layers': 3, 'hidden_layer_size': 368, 'learning_rate': 0.011041967583530028}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:13,350] Trial 16 finished with value: 1.2552994322624935 and parameters: {'num_layers': 2, 'hidden_layer_size': 204, 'learning_rate': 0.032464179813587714}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:17,233] Trial 17 finished with value: 0.24956710857285816 and parameters: {'num_layers': 3, 'hidden_layer_size': 106, 'learning_rate': 0.0074474694077294405}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:21,223] Trial 18 finished with value: 0.4037027608626967 and parameters: {'num_layers': 3, 'hidden_layer_size': 110, 'learning_rate': 0.02114741680642665}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:26,887] Trial 19 finished with value: 0.47724595789317115 and parameters: {'num_layers': 4, 'hidden_layer_size': 426, 'learning_rate': 0.011300913584548296}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:31,668] Trial 20 finished with value: 1.039662808369679 and parameters: {'num_layers': 3, 'hidden_layer_size': 318, 'learning_rate': 0.03533943240288361}. Best is trial 2 with value: 0.24748259308231865.\n",
      "[I 2025-03-10 22:55:35,870] Trial 21 finished with value: 0.18162940161385735 and parameters: {'num_layers': 2, 'hidden_layer_size': 96, 'learning_rate': 0.0036495723110907133}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:55:40,434] Trial 22 finished with value: 0.2944535119518353 and parameters: {'num_layers': 3, 'hidden_layer_size': 231, 'learning_rate': 0.010168279909405848}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:55:44,380] Trial 23 finished with value: 0.26283749259688005 and parameters: {'num_layers': 2, 'hidden_layer_size': 120, 'learning_rate': 0.007101385985958477}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:55:48,406] Trial 24 finished with value: 0.4568400300422292 and parameters: {'num_layers': 3, 'hidden_layer_size': 79, 'learning_rate': 0.020141507727982382}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:55:52,356] Trial 25 finished with value: 0.5921211539749887 and parameters: {'num_layers': 2, 'hidden_layer_size': 151, 'learning_rate': 0.028351141178697234}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:55:56,760] Trial 26 finished with value: 0.32655070267712616 and parameters: {'num_layers': 3, 'hidden_layer_size': 236, 'learning_rate': 0.006909998211914584}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:01,957] Trial 27 finished with value: 0.9221840151555979 and parameters: {'num_layers': 4, 'hidden_layer_size': 318, 'learning_rate': 0.03934960088577829}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:05,968] Trial 28 finished with value: 0.5953193259466986 and parameters: {'num_layers': 2, 'hidden_layer_size': 106, 'learning_rate': 0.023096629584238533}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:10,005] Trial 29 finished with value: 0.24184026827762842 and parameters: {'num_layers': 1, 'hidden_layer_size': 87, 'learning_rate': 0.0009167822402008675}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:13,939] Trial 30 finished with value: 1.3091722320599162 and parameters: {'num_layers': 1, 'hidden_layer_size': 60, 'learning_rate': 0.050564168652807925}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:17,753] Trial 31 finished with value: 0.32613624622867365 and parameters: {'num_layers': 1, 'hidden_layer_size': 88, 'learning_rate': 0.00022245106450015546}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:21,573] Trial 32 finished with value: 0.23507320807333204 and parameters: {'num_layers': 1, 'hidden_layer_size': 152, 'learning_rate': 0.0069954849619508356}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:25,526] Trial 33 finished with value: 0.1983863349031111 and parameters: {'num_layers': 1, 'hidden_layer_size': 174, 'learning_rate': 0.004601094623808133}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:29,345] Trial 34 finished with value: 0.3958435316753995 and parameters: {'num_layers': 1, 'hidden_layer_size': 156, 'learning_rate': 0.015843157646743638}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:33,142] Trial 35 finished with value: 0.2064810063167932 and parameters: {'num_layers': 1, 'hidden_layer_size': 144, 'learning_rate': 0.00447701486121346}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:36,953] Trial 36 finished with value: 0.20682135259934292 and parameters: {'num_layers': 1, 'hidden_layer_size': 154, 'learning_rate': 0.005421036863589507}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:40,875] Trial 37 finished with value: 2.1987609939210735 and parameters: {'num_layers': 1, 'hidden_layer_size': 207, 'learning_rate': 0.09125974340148679}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:44,713] Trial 38 finished with value: 0.32165382394365444 and parameters: {'num_layers': 1, 'hidden_layer_size': 178, 'learning_rate': 0.014994557019630476}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:48,669] Trial 39 finished with value: 1.84165185120455 and parameters: {'num_layers': 1, 'hidden_layer_size': 210, 'learning_rate': 0.07962199195436521}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:52,496] Trial 40 finished with value: 1.5331508665327813 and parameters: {'num_layers': 1, 'hidden_layer_size': 141, 'learning_rate': 0.051837357212889186}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:56:56,353] Trial 41 finished with value: 2.095566097338488 and parameters: {'num_layers': 1, 'hidden_layer_size': 162, 'learning_rate': 0.09913329485445443}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:00,250] Trial 42 finished with value: 0.19535582645493707 and parameters: {'num_layers': 1, 'hidden_layer_size': 136, 'learning_rate': 0.005185054359252251}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:04,010] Trial 43 finished with value: 0.30875886497414035 and parameters: {'num_layers': 1, 'hidden_layer_size': 63, 'learning_rate': 0.00433824000509309}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:07,988] Trial 44 finished with value: 0.2814738084651103 and parameters: {'num_layers': 1, 'hidden_layer_size': 234, 'learning_rate': 0.012897031968808901}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:11,931] Trial 45 finished with value: 0.1974310713588812 and parameters: {'num_layers': 1, 'hidden_layer_size': 132, 'learning_rate': 0.003967939760023728}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:15,997] Trial 46 finished with value: 0.4135405945170457 and parameters: {'num_layers': 2, 'hidden_layer_size': 186, 'learning_rate': 0.018344951972728406}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:20,076] Trial 47 finished with value: 0.6640665962058268 and parameters: {'num_layers': 1, 'hidden_layer_size': 133, 'learning_rate': 0.026202363391925745}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:23,967] Trial 48 finished with value: 0.29369186021529947 and parameters: {'num_layers': 1, 'hidden_layer_size': 55, 'learning_rate': 0.002717461651136794}. Best is trial 21 with value: 0.18162940161385735.\n",
      "[I 2025-03-10 22:57:27,890] Trial 49 finished with value: 0.34727989284286076 and parameters: {'num_layers': 2, 'hidden_layer_size': 98, 'learning_rate': 0.010521223810559307}. Best is trial 21 with value: 0.18162940161385735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_layers': 2, 'hidden_layer_size': 96, 'learning_rate': 0.0036495723110907133}\n"
     ]
    }
   ],
   "source": [
    "# Set up the Optuna study\n",
    "study = optuna.create_study(direction='minimize')  # For loss, or 'maximize' for accuracy\n",
    "study.optimize(objective, n_trials=50)  # You can change n_trials for more trials\n",
    "\n",
    "# Best hyperparameters found\n",
    "print(f\"Best hyperparameters: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2e19a194-4f00-4556-8811-d2bcc9799a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_layers': 2, 'hidden_layer_size': 96, 'learning_rate': 0.0036495723110907133}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Retrieve best hyperparameters found by Optuna\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Step 2: Set up the model using the best hyperparameters\n",
    "input_size = 28 * 28  # Input size for the FashionMNIST dataset\n",
    "output_size = 10  # Number of classes in the FashionMNIST dataset\n",
    "\n",
    "# Extract best parameters\n",
    "hidden_layers = []\n",
    "num_layers = best_params[\"num_layers\"]  # Number of layers\n",
    "for _ in range(num_layers):\n",
    "    hidden_layers.append(best_params[\"hidden_layer_size\"])  # Number of neurons per hidden layer\n",
    "learning_rate = best_params[\"learning_rate\"]\n",
    "\n",
    "# Create the model\n",
    "model = MLP(input_size, hidden_layers, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5c38d877-b0c5-41be-8578-40294e63743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss with best parameters: 0.1303398988248387\n",
      "Validation Loss: 0.1473248930066634\n",
      "Validation Accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model using the best hyperparameters\n",
    "# Train the model on your dataset\n",
    "train_loss = train_model(model, train_dataloader, learning_rate=learning_rate)\n",
    "print(f\"Training loss with best parameters: {train_loss}\")\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "val_loss, val_accuracy = evaluate_model(model, test_dataloader)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d2571dd8-a5d1-46a4-8a8a-01e42af0fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to display a grid of images and their predicted labels\n",
    "def plot_images_with_labels(model, dataloader, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    images, labels = next(iter(dataloader))  # Sample a batch from the dataloader\n",
    "\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    images = images.view(images.shape[0], -1)  # Flatten the images (28*28)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    logits = model(images)\n",
    "    predicted_labels = logits.argmax(dim=1)  # Get the predicted labels\n",
    "\n",
    "    # Plot images and labels\n",
    "    figure = plt.figure(figsize=(10, 10))\n",
    "    for i in range(10):  # Show the first 10 images in the batch\n",
    "        ax = figure.add_subplot(2, 5, i + 1)  # Create a 2x5 grid\n",
    "        ax.imshow(images[i].cpu().view(28, 28).detach().numpy(), cmap=\"gray\")\n",
    "        ax.set_title(f\"True: {labels[i].item()}, Pred: {predicted_labels[i].item()}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Sample usage: Call this function after training your model\n",
    "plot_images_with_labels(model, test_dataloader, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d3126-e850-4274-a857-477ff2978e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
