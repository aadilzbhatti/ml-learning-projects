{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdba6d74-f9e7-4132-bfa3-b99dcdb61dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3c83bfb-a31a-408e-b128-d7fb4eed7e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('makemore/names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a98fd9b-e53c-4990-86fe-1d12518f85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "def build_dataset(words, block_size):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "    \n",
    "        # print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i + 1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff7dba65-ea17-4d14-a7b8-fe4638361bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(steps, batch_size, learning_rate, l1_num_inputs, x, y, stepi, lossi):\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "    for i in range(steps):\n",
    "        ix = torch.randint(0, x.shape[0], (batch_size,))\n",
    "        \n",
    "        # Forward pass\n",
    "        emb = C[x[ix]]  # Shape: (batch_size, block_size, embedding_dims)\n",
    "        emb = emb.view(batch_size, -1)  # Flatten properly\n",
    "        \n",
    "        h = torch.tanh(emb @ W1 + b1)  # Now matches shape (batch_size, l2_num_neurons)\n",
    "        logits = h @ W2 + b2  # Shape: (batch_size, 27)\n",
    "        loss = F.cross_entropy(logits, y[ix])\n",
    "        \n",
    "        # Backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += -learning_rate * p.grad\n",
    "\n",
    "        stepi.append(i)\n",
    "        lossi.append(loss.log10().item())\n",
    "\n",
    "\n",
    "def total_loss(x, y, l1_num_inputs):\n",
    "    emb = C[x] # (batch_size, block_size, l1_num_inputs)\n",
    "    h = torch.tanh(emb.view(-1, l1_num_inputs) @ W1 + b1) # (l1_num_inputs, l2_num_neurons)\n",
    "    logits = h @ W2 + b2 # (batch_size, 27)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d34bf50e-b7f4-44d2-9074-e766bb632f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(num_samples):\n",
    "    # sample from the model\n",
    "    g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "    \n",
    "    for _ in range(20):\n",
    "    \n",
    "        out = []\n",
    "        context = [0] * block_size # initialize with all ...\n",
    "        while True:\n",
    "            emb = C[torch.tensor([context])] # (1, block_size, d)\n",
    "            h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "            logits = h @ W2 + b2\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "            context = context[1:] + [ix]\n",
    "            out.append(ix)\n",
    "            if ix == 0:\n",
    "                break\n",
    "    \n",
    "        print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74e43756-4e20-477f-98b9-1be099fa8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    block_size = trial.suggest_int(\"block_size\", 8, 12)  # Context length\n",
    "    embedding_dims = trial.suggest_int(\"embedding_dims\", 8, 12)  # Embedding size\n",
    "    l2_num_neurons = trial.suggest_int(\"l2_num_neurons\", 50, 150)  # Hidden layer size\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])  # Batch size\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 1e-1, log=True)  # Learning rate\n",
    "\n",
    "    # Build datasets with new block_size\n",
    "    Xtr, Ytr = build_dataset(words[:n1], block_size)\n",
    "    Xdev, Ydev = build_dataset(words[n1:n2], block_size)\n",
    "\n",
    "    # Define model parameters\n",
    "    l1_num_inputs = embedding_dims * block_size\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    \n",
    "    global C, W1, b1, W2, b2  # Ensure variables are accessible\n",
    "    C = torch.randn((27, embedding_dims), generator=g)\n",
    "    W1 = torch.randn((l1_num_inputs, l2_num_neurons), generator=g)\n",
    "    b1 = torch.randn(l2_num_neurons, generator=g)\n",
    "    W2 = torch.randn((l2_num_neurons, 27), generator=g)\n",
    "    b2 = torch.randn(27, generator=g)\n",
    "    \n",
    "    parameters = [C, W1, b1, W2, b2]\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(50000):  # Reduce iterations for speed\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "        emb = C[Xtr[ix]]\n",
    "        h = torch.tanh(emb.view(-1, l1_num_inputs) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Ytr[ix])\n",
    "\n",
    "        # Backprop\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += -learning_rate * p.grad\n",
    "\n",
    "    # Compute validation loss\n",
    "    val_loss = total_loss(Xdev, Ydev, l1_num_inputs)\n",
    "    \n",
    "    return val_loss  # Optuna minimizes by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9502942f-dfa0-46c6-ab3f-963386b73454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:05:28,172] A new study created in memory with name: no-name-55c65799-95c8-4a8b-8db3-ac793ef8ab40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 10]) torch.Size([182778])\n",
      "torch.Size([22633, 10]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:05:35,737] Trial 0 finished with value: 2.6170952320098877 and parameters: {'block_size': 10, 'embedding_dims': 10, 'l2_num_neurons': 60, 'batch_size': 32, 'learning_rate': 0.050675099941790085}. Best is trial 0 with value: 2.6170952320098877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 10]) torch.Size([182778])\n",
      "torch.Size([22633, 10]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:05:44,663] Trial 1 finished with value: 2.6354153156280518 and parameters: {'block_size': 10, 'embedding_dims': 9, 'l2_num_neurons': 148, 'batch_size': 64, 'learning_rate': 0.0668998711142591}. Best is trial 0 with value: 2.6170952320098877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:05:52,874] Trial 2 finished with value: 2.5692782402038574 and parameters: {'block_size': 9, 'embedding_dims': 9, 'l2_num_neurons': 111, 'batch_size': 64, 'learning_rate': 0.029995485554564827}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 11]) torch.Size([182778])\n",
      "torch.Size([22633, 11]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:01,944] Trial 3 finished with value: 2.7104671001434326 and parameters: {'block_size': 11, 'embedding_dims': 12, 'l2_num_neurons': 64, 'batch_size': 64, 'learning_rate': 0.01179814900105327}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 10]) torch.Size([182778])\n",
      "torch.Size([22633, 10]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:09,952] Trial 4 finished with value: 2.6507132053375244 and parameters: {'block_size': 10, 'embedding_dims': 11, 'l2_num_neurons': 138, 'batch_size': 32, 'learning_rate': 0.04380368997709687}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 10]) torch.Size([182778])\n",
      "torch.Size([22633, 10]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:18,998] Trial 5 finished with value: 2.590683937072754 and parameters: {'block_size': 10, 'embedding_dims': 9, 'l2_num_neurons': 118, 'batch_size': 64, 'learning_rate': 0.022109186319559136}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 11]) torch.Size([182778])\n",
      "torch.Size([22633, 11]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:27,437] Trial 6 finished with value: 2.6831870079040527 and parameters: {'block_size': 11, 'embedding_dims': 10, 'l2_num_neurons': 83, 'batch_size': 64, 'learning_rate': 0.014803571655093887}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 12]) torch.Size([182778])\n",
      "torch.Size([22633, 12]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:35,290] Trial 7 finished with value: 2.815549373626709 and parameters: {'block_size': 12, 'embedding_dims': 8, 'l2_num_neurons': 75, 'batch_size': 32, 'learning_rate': 0.028701207485083802}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:42,508] Trial 8 finished with value: 2.609130382537842 and parameters: {'block_size': 8, 'embedding_dims': 9, 'l2_num_neurons': 96, 'batch_size': 16, 'learning_rate': 0.024232063581398226}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 12]) torch.Size([182778])\n",
      "torch.Size([22633, 12]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:51,445] Trial 9 finished with value: 2.68961501121521 and parameters: {'block_size': 12, 'embedding_dims': 8, 'l2_num_neurons': 90, 'batch_size': 64, 'learning_rate': 0.011725269925454284}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:06:59,126] Trial 10 finished with value: 2.730764150619507 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 111, 'batch_size': 16, 'learning_rate': 0.08575808815031853}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:07:08,580] Trial 11 finished with value: 2.6047770977020264 and parameters: {'block_size': 9, 'embedding_dims': 9, 'l2_num_neurons': 120, 'batch_size': 64, 'learning_rate': 0.020550291046911945}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:07:17,016] Trial 12 finished with value: 2.5981767177581787 and parameters: {'block_size': 9, 'embedding_dims': 9, 'l2_num_neurons': 122, 'batch_size': 64, 'learning_rate': 0.03544218319969736}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:07:25,523] Trial 13 finished with value: 2.6111576557159424 and parameters: {'block_size': 9, 'embedding_dims': 8, 'l2_num_neurons': 105, 'batch_size': 64, 'learning_rate': 0.018410111096850753}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:07:35,799] Trial 14 finished with value: 2.602823495864868 and parameters: {'block_size': 9, 'embedding_dims': 10, 'l2_num_neurons': 133, 'batch_size': 64, 'learning_rate': 0.032234210095418776}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 11]) torch.Size([182778])\n",
      "torch.Size([22633, 11]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:07:43,430] Trial 15 finished with value: 2.6976583003997803 and parameters: {'block_size': 11, 'embedding_dims': 9, 'l2_num_neurons': 122, 'batch_size': 16, 'learning_rate': 0.018099580715354967}. Best is trial 2 with value: 2.5692782402038574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:07:52,486] Trial 16 finished with value: 2.552072525024414 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 110, 'batch_size': 64, 'learning_rate': 0.04181795266581569}. Best is trial 16 with value: 2.552072525024414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:01,476] Trial 17 finished with value: 2.5411388874053955 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 102, 'batch_size': 64, 'learning_rate': 0.05572763019715074}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:08,370] Trial 18 finished with value: 2.764185667037964 and parameters: {'block_size': 8, 'embedding_dims': 12, 'l2_num_neurons': 96, 'batch_size': 16, 'learning_rate': 0.05762368423480465}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:15,737] Trial 19 finished with value: 2.583416700363159 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 76, 'batch_size': 32, 'learning_rate': 0.09471611724987403}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:23,715] Trial 20 finished with value: 2.6038193702697754 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 52, 'batch_size': 64, 'learning_rate': 0.040844920489376074}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:32,298] Trial 21 finished with value: 2.6122822761535645 and parameters: {'block_size': 9, 'embedding_dims': 10, 'l2_num_neurons': 107, 'batch_size': 64, 'learning_rate': 0.07140580354816159}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:41,219] Trial 22 finished with value: 2.544375419616699 and parameters: {'block_size': 8, 'embedding_dims': 12, 'l2_num_neurons': 111, 'batch_size': 64, 'learning_rate': 0.046218065496292864}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:50,691] Trial 23 finished with value: 2.6001038551330566 and parameters: {'block_size': 8, 'embedding_dims': 12, 'l2_num_neurons': 131, 'batch_size': 64, 'learning_rate': 0.04644252971688768}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:08:59,297] Trial 24 finished with value: 2.5592217445373535 and parameters: {'block_size': 8, 'embedding_dims': 12, 'l2_num_neurons': 101, 'batch_size': 64, 'learning_rate': 0.06043038502595976}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:09:08,521] Trial 25 finished with value: 2.559724807739258 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 91, 'batch_size': 64, 'learning_rate': 0.03825097294320879}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:09:18,887] Trial 26 finished with value: 2.630140781402588 and parameters: {'block_size': 9, 'embedding_dims': 12, 'l2_num_neurons': 116, 'batch_size': 64, 'learning_rate': 0.051134736034429355}. Best is trial 17 with value: 2.5411388874053955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:09:27,320] Trial 27 finished with value: 2.5282766819000244 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 87, 'batch_size': 64, 'learning_rate': 0.07081949491424479}. Best is trial 27 with value: 2.5282766819000244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:09:35,024] Trial 28 finished with value: 2.5792806148529053 and parameters: {'block_size': 9, 'embedding_dims': 11, 'l2_num_neurons': 82, 'batch_size': 32, 'learning_rate': 0.07740959312899753}. Best is trial 27 with value: 2.5282766819000244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:09:42,165] Trial 29 finished with value: 2.6839208602905273 and parameters: {'block_size': 8, 'embedding_dims': 12, 'l2_num_neurons': 68, 'batch_size': 16, 'learning_rate': 0.05254943336374956}. Best is trial 27 with value: 2.5282766819000244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 9]) torch.Size([182778])\n",
      "torch.Size([22633, 9]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:09:49,546] Trial 30 finished with value: 2.6952197551727295 and parameters: {'block_size': 9, 'embedding_dims': 10, 'l2_num_neurons': 87, 'batch_size': 32, 'learning_rate': 0.0996781866615738}. Best is trial 27 with value: 2.5282766819000244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 15:09:57,788] Trial 31 finished with value: 2.514582872390747 and parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 100, 'batch_size': 64, 'learning_rate': 0.06515495056860778}. Best is trial 31 with value: 2.514582872390747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-01 15:10:05,404] Trial 32 failed with parameters: {'block_size': 8, 'embedding_dims': 11, 'l2_num_neurons': 100, 'batch_size': 64, 'learning_rate': 0.0639699936805835} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/8_/kl72rt_d67z2yxqnyg9_n3mw0000gn/T/ipykernel_25469/175724720.py\", line 39, in objective\n",
      "    loss.backward()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        tensors,\n",
      "        ^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        accumulate_grad=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        t_outputs, *args, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )  # Calls into the C++ engine to run the backward pass\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-01 15:10:05,408] Trial 32 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Try 30 different sets of hyperparameters\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[55], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     38\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     42\u001b[0m     p\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)  # Try 30 different sets of hyperparameters\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534ca7f-af3f-443b-8e8d-693ddd808710",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params  # Get the best hyperparams from Optuna\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "block_size = best_params[\"block_size\"]\n",
    "embedding_dims = best_params[\"embedding_dims\"]\n",
    "l2_num_neurons = best_params[\"l2_num_neurons\"]\n",
    "\n",
    "l1_num_inputs = embedding_dims * block_size\n",
    "\n",
    "# Reinitialize parameters using the best hyperparameters\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, embedding_dims), generator=g)\n",
    "W1 = torch.randn((l1_num_inputs, l2_num_neurons), generator=g)\n",
    "b1 = torch.randn(l2_num_neurons, generator=g)\n",
    "W2 = torch.randn((l2_num_neurons, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e71b70-8e0b-4123-bc5d-3b2529e3d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr = build_dataset(words[:n1], block_size)\n",
    "Xdev, Ydev = build_dataset(words[n1:n2], block_size)\n",
    "Xte, Yte = build_dataset(words[n2:], block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbcdf6-90f1-452a-8d5f-2bf74c1ca259",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepi = []\n",
    "lossi = []\n",
    "train_model(\n",
    "    steps=100000,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    l1_num_inputs=l1_num_inputs,\n",
    "    x=Xtr,\n",
    "    y=Ytr,\n",
    "    stepi=stepi,\n",
    "    lossi=lossi\n",
    ")\n",
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435734d-6efc-40b2-9e8a-7e52b05aca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training loss:\", total_loss(Xtr, Ytr, l1_num_inputs))\n",
    "print(\"Validation loss:\", total_loss(Xdev, Ydev, l1_num_inputs))\n",
    "print(\"Test loss:\", total_loss(Xte, Yte, l1_num_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014363b-0ef0-4b77-847e-a205681929c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
